<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Tinka</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 600px;
            margin: 0 auto;
            padding: 20px;
            text-align: center;
            position: relative;
        }
        .settings-dropdown {
            position: absolute;
            top: 60px;
            right: 20px;
            background: white;
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 10px;
            display: none;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
            z-index: 1000;
        }
        .settings-dropdown.active {
            display: block;
        }
        .settings-option {
            padding: 8px 15px;
            cursor: pointer;
            white-space: nowrap;
            display: flex;
            align-items: center;
            gap: 8px;
        }
        .settings-option:hover {
            background: #f5f5f5;
        }
        .settings-option.active {
            color: #4CAF50;
            font-weight: bold;
        }
        .view-toggle {
            display: none;
        }
        .view-toggle.active {
            display: block;
        }
        .container {
            margin-top: 30px;
        }
        #recordButton {
            border-radius: 50%;
            background-color: #f44336;
            color: white;
            font-size: 18px;
            border: none;
            cursor: pointer;
            transition: transform 0.1s, background-color 0.3s;
            display: flex;
            align-items: center;
            justify-content: center;
            margin: 0 auto;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);
        }
        #recordButton:active {
            transform: scale(0.95);
            background-color: #d32f2f;
        }
        #recordButton.recording {
            background-color: #d32f2f;
            animation: pulse 1.5s infinite;
        }
        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(0.95); }
            100% { transform: scale(1); }
        }
        #timer {
            font-size: 24px;
            margin: 20px 0;
        }
        #audioElement {
            width: 100%;
            margin-top: 20px;
        }
        .status {
            margin-top: 10px;
            font-style: italic;
        }
        .recording-list {
            margin-top: 30px;
            text-align: left;
            max-height: 300px;
            overflow-y: auto;
            border: 1px solid #ddd;
            padding: 10px;
            border-radius: 5px;
        }
        .recording-item {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 10px;
            border-bottom: 1px solid #eee;
        }
        .recording-item:last-child {
            border-bottom: none;
        }
        /* OpenAI API section styles */
        .openai-section {
            margin-top: 20px;
            margin-bottom: 30px;
            display: flex;
            flex-direction: column;
        }
        .openai-input {
            width: 100%;
            padding: 10px;
            margin: 10px 0;
            border: 1px solid #ccc;
            border-radius: 4px;
            font-size: 16px;
            box-sizing: border-box;
        }
        .openai-button {
            background-color: #4CAF50;
            color: white;
            padding: 0;
            border: none;
            border-radius: 20px;
            cursor: pointer;
            font-size: 16px;
            margin: 10px;
            width: 40px;
            height: 40px;
            display: flex;
            align-items: center;
            justify-content: center;
        }
        .openai-button:hover {
            background-color: #45a049;
        }
        .openai-response {
            width: 100%;
            padding: 10px;
            margin: 10px 0;
            border: 1px solid #ddd;
            border-radius: 4px;
            text-align: left;
            height: 70vh;
            overflow-y: auto;
            background-color: #f9f9f9;
            display: flex;
            flex-direction: column;
        }
        .message {
            margin-bottom: 10px;
            padding: 8px 12px;
            border-radius: 8px;
            max-width: 80%;
        }
        .user-message {
            background-color: #e1f5fe;
            align-self: flex-end;
            border-bottom-right-radius: 0;
        }
        .assistant-message {
            background-color: #f1f1f1;
            align-self: flex-start;
            border-bottom-left-radius: 0;
        }
        .input-container {
            display: flex;
            align-items: center;
            margin-top: 10px;
            width: 100%;
        }
        .input-container textarea {
            flex-grow: 1;
            margin-left: 10px;
            resize: none;
            height: 40px;
            padding: 10px;
            border: 1px solid #ccc;
            border-radius: 20px;
            font-size: 16px;
            transition: border-color 0.3s ease;
        }
        .input-container textarea.recording {
            border-color: #f44336;
            box-shadow: 0 0 5px rgba(244, 67, 54, 0.5);
        }
        .input-container button {
            margin-left: 10px;
            border-radius: 20px;
            height: 40px;
            width: 40px;
            padding: 0;
            display: flex;
            align-items: center;
            justify-content: center;
        }
        .mic-button {
            background-color: #f44336;
            color: white;
            margin-right: 10px;
        }
        .mic-button.recording {
            background-color: #d32f2f;
            animation: pulse 1.5s infinite;
        }
        .mic-button:active {
            transform: scale(0.95);
        }
        .camera-button {
            background-color: #2196F3;
            color: white;
        }
        .camera-button:active {
            transform: scale(0.95);
        }
        .camera-button.recording {
            background-color: #0b7dda;
            animation: pulse 1.5s infinite;
        }
        .loading {
            display: inline-block;
            width: 20px;
            height: 20px;
            border: 3px solid rgba(0,0,0,.1);
            border-radius: 50%;
            border-top-color: #4CAF50;
            animation: spin 1s ease-in-out infinite;
            margin-right: 10px;
        }
        @keyframes spin {
            to { transform: rotate(360deg); }
        }
        /* Photo preview styles */
        .photo-preview-container {
            display: flex;
            flex-direction: column;
            align-items: center;
            margin-top: 10px;
            width: 100%;
        }
        .photo-preview {
            max-width: 100%;
            max-height: 200px;
            border-radius: 8px;
            border: 1px solid #ddd;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
            display: none;
        }
        .photo-preview.visible {
            display: block;
        }
        .photo-preview-label {
            font-size: 14px;
            color: #666;
            margin-bottom: 5px;
        }
        /* Tab styles */
        .tabs {
            margin: 20px 0;
            border-bottom: 1px solid #ddd;
        }
        .tab-button {
            padding: 10px 20px;
            border: none;
            background: none;
            cursor: pointer;
            font-size: 16px;
            color: #666;
            position: relative;
        }
        .tab-button.active {
            color: #4CAF50;
        }
        .tab-button.active::after {
            content: '';
            position: absolute;
            bottom: -1px;
            left: 0;
            right: 0;
            height: 2px;
            background-color: #4CAF50;
        }
        .tab-content {
            display: none;
        }
        .tab-content.active {
            display: block;
        }
        .conversation-controls {
            display: flex;
            justify-content: flex-end;
            margin-bottom: 10px;
        }
        .new-conversation-btn {
            background-color: #2196F3;
            color: white;
            padding: 8px 12px;
            border: none;
            border-radius: 4px;
            cursor: pointer;
            font-size: 14px;
            display: flex;
            align-items: center;
            gap: 5px;
        }
        .new-conversation-btn:hover {
            background-color: #0b7dda;
        }
        .top-controls {
            position: absolute;
            top: 20px;
            right: 20px;
            display: flex;
            gap: 10px;
            align-items: center;
            z-index: 100;
        }
        .icon-button {
            width: 30px;
            height: 30px;
            display: flex;
            align-items: center;
            justify-content: center;
            border-radius: 50%;
            cursor: pointer;
            transition: transform 0.3s ease;
            border: none;
            padding: 0;
            position: relative;
            z-index: 100;
        }
        .new-conversation-icon {
            background-color: #2196F3;
            color: white;
        }
        .new-conversation-icon:hover {
            background-color: #0b7dda;
            transform: rotate(45deg);
        }
    </style>
</head>
<body>
    <div class="top-controls">
        <button id="newConversationBtn" class="icon-button new-conversation-icon" title="New Conversation">
            <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                <line x1="12" y1="5" x2="12" y2="19"></line>
                <line x1="5" y1="12" x2="19" y2="12"></line>
            </svg>
        </button>
        <div class="icon-button" id="settingsIcon">
            <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                <circle cx="12" cy="12" r="3"></circle>
                <path d="M19.4 15a1.65 1.65 0 0 0 .33 1.82l.06.06a2 2 0 0 1 0 2.83 2 2 0 0 1-2.83 0l-.06-.06a1.65 1.65 0 0 0-1.82-.33 1.65 1.65 0 0 0-1 1.51V21a2 2 0 0 1-2 2 2 2 0 0 1-2-2v-.09A1.65 1.65 0 0 0 9 19.4a1.65 1.65 0 0 0-1.82.33l-.06.06a2 2 0 0 1-2.83 0 2 2 0 0 1 0-2.83l.06-.06a1.65 1.65 0 0 0 .33-1.82 1.65 1.65 0 0 0-1.51-1H3a2 2 0 0 1-2-2 2 2 0 0 1 2-2h.09A1.65 1.65 0 0 0 4.6 9a1.65 1.65 0 0 0-.33-1.82l-.06-.06a2 2 0 0 1 0-2.83 2 2 0 0 1 2.83 0l.06.06a1.65 1.65 0 0 0 1.82.33H9a1.65 1.65 0 0 0 1-1.51V3a2 2 0 0 1 2-2 2 2 0 0 1 2 2v.09a1.65 1.65 0 0 0 1 1.51 1.65 1.65 0 0 0 1.82-.33l.06-.06a2 2 0 0 1 2.83 0 2 2 0 0 1 0 2.83l-.06.06a1.65 1.65 0 0 0-.33 1.82V9a1.65 1.65 0 0 0 1.51 1H21a2 2 0 0 1 2 2 2 2 0 0 1-2 2h-.09a1.65 1.65 0 0 0-1.51 1z"></path>
            </svg>
        </div>
    </div>
    <div class="settings-dropdown" id="settingsDropdown">
        <div class="settings-option active" data-view="main">
            <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                <rect x="3" y="3" width="18" height="18" rx="2" ry="2"></rect>
                <line x1="3" y1="9" x2="21" y2="9"></line>
                <line x1="9" y1="21" x2="9" y2="9"></line>
            </svg>
            Main View
        </div>
        <div class="settings-option" data-view="developer">
            <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                <polyline points="16 18 22 12 16 6"></polyline>
                <polyline points="8 6 2 12 8 18"></polyline>
            </svg>
            Developer View
        </div>
    </div>

    <h1>Tinka</h1>
    
    <!-- OpenAI API Section - Moved to top and restructured -->
    <div class="openai-section">
        <div id="openaiResponse" class="openai-response">
            <div class="message assistant-message"></div>
        </div>
        <div class="input-container">
            <textarea id="openaiInput" class="openai-input" placeholder="Type your message here..." rows="1"></textarea>
            <button id="sendToOpenAI" class="openai-button">
                <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                    <line x1="22" y1="2" x2="11" y2="13"></line>
                    <polygon points="22 2 15 22 11 13 2 9 22 2"></polygon>
                </svg>
            </button>
            <button id="recordButton" class="openai-button mic-button" title="Press and hold to record">
                <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                    <path d="M12 1a3 3 0 0 0-3 3v8a3 3 0 0 0 6 0V4a3 3 0 0 0-3-3z"></path>
                    <path d="M19 10v2a7 7 0 0 1-14 0v-2"></path>
                    <line x1="12" y1="19" x2="12" y2="23"></line>
                    <line x1="8" y1="23" x2="16" y2="23"></line>
                </svg>
            </button>
            <button id="cameraButton" class="openai-button camera-button" title="Take a photo">
                <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                    <path d="M23 19a2 2 0 0 1-2 2H3a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h4l2-3h6l2 3h4a2 2 0 0 1 2 2z"></path>
                    <circle cx="12" cy="13" r="4"></circle>
                </svg>
            </button>
        </div>
    </div>
    

    <!-- Developer View Content -->
    <div id="developerView" class="view-toggle">
        <div class="photo-preview-container">
            <div class="photo-preview-label">Last photo taken:</div>
            <img id="photoPreview" class="photo-preview" alt="Last photo taken">
        </div>
    <div class="container">
        <div id="timer">00:00</div>
        <p class="status" id="status">Ready to record</p>
        
        <audio id="audioElement" controls></audio>
    </div>

        <div class="recording-list" id="recordingList">
            <h3>Your Recordings</h3>
            <div id="recordingsContainer">
                <p>No recordings yet.</p>
            </div>
        </div>
    </div>

    <script>
        // DOM elements
        const recordButton = document.getElementById('recordButton');
        const audioElement = document.getElementById('audioElement');
        const timerElement = document.getElementById('timer');
        const statusElement = document.getElementById('status');
        const recordingsContainer = document.getElementById('recordingsContainer');
        
        // OpenAI elements
        const openaiInput = document.getElementById('openaiInput');
        const sendToOpenAIButton = document.getElementById('sendToOpenAI');
        const openaiResponse = document.getElementById('openaiResponse');
        const newConversationBtn = document.getElementById('newConversationBtn');
        const cameraButton = document.getElementById('cameraButton');
        const photoPreview = document.getElementById('photoPreview');

        // Settings functionality
        const settingsIcon = document.getElementById('settingsIcon');
        const settingsDropdown = document.getElementById('settingsDropdown');
        const settingsOptions = document.querySelectorAll('.settings-option');
        const developerView = document.getElementById('developerView');

        // Variables for recording
        let mediaRecorder;
        let audioChunks = [];
        let audioBlob;
        let audioUrl;
        let startTime;
        let timerInterval;
        let stream;
        let recordingCount = 0;
        let recognition; // Web Speech API recognition object
        let messages = []; // Array to store conversation history
        let cameraStream; // For camera access

        // Cookie functions
        function setCookie(name, value, days) {
            let expires = "";
            if (days) {
                const date = new Date();
                date.setTime(date.getTime() + (days * 24 * 60 * 60 * 1000));
                expires = "; expires=" + date.toUTCString();
            }
            document.cookie = name + "=" + (value || "") + expires + "; path=/";
        }

        function getCookie(name) {
            const nameEQ = name + "=";
            const ca = document.cookie.split(';');
            for (let i = 0; i < ca.length; i++) {
                let c = ca[i];
                while (c.charAt(0) === ' ') c = c.substring(1, c.length);
                if (c.indexOf(nameEQ) === 0) return c.substring(nameEQ.length, c.length);
            }
            return null;
        }

        function deleteCookie(name) {
            document.cookie = name + '=; Max-Age=-99999999; path=/';
        }

        // Function to scroll to bottom of response area
        function scrollToBottom() {
            openaiResponse.scrollTop = openaiResponse.scrollHeight;
        }

        // Load conversation from cookie on page load
        function loadConversation() {
            const savedConversation = getCookie('openaiConversation');
            if (savedConversation) {
                try {
                    const conversation = JSON.parse(savedConversation);
                    openaiResponse.innerHTML = '';
                    messages = []; // Clear existing messages
                    
                    conversation.forEach((msg, index) => {
                        const messageDiv = document.createElement('div');
                        messageDiv.className = `message ${msg.role}-message`;
                        
                        // Check if this is a photo message
                        if (msg.role === 'user' && msg.content === '[Photo]') {
                            // Try to get the image from localStorage
                            const imageData = localStorage.getItem(`photo_${index}`);
                            
                            if (imageData) {
                                // Create an image element
                                const imgElement = document.createElement('img');
                                imgElement.src = imageData;
                                imgElement.alt = 'User photo';
                                imgElement.style.maxWidth = '100%';
                                imgElement.style.borderRadius = '4px';
                                imgElement.style.marginTop = '5px';
                                
                                // Add the image to the message
                                messageDiv.appendChild(imgElement);
                            } else {
                                // Fallback if image data is not found
                                messageDiv.textContent = '[Photo]';
                            }
                        } else {
                            // Regular text message
                            messageDiv.textContent = msg.content;
                        }
                        
                        openaiResponse.appendChild(messageDiv);
                        
                        // Add to messages array
                        messages.push({
                            role: msg.role,
                            text: msg.content
                        });
                    });
                    
                    // Scroll to bottom
                    scrollToBottom();
                } catch (e) {
                    console.error('Error loading conversation:', e);
                }
            }
        }

        // Save conversation to cookie
        function saveConversation() {
            setCookie('openaiConversation', JSON.stringify(messages), 7); // Save for 7 days
        }

        // Start a new conversation
        function startNewConversation() {
            openaiResponse.innerHTML = '<div class="message assistant-message"></div>';
            messages = []; // Clear messages array
            deleteCookie('openaiConversation');
            saveConversation(); // Save the initial message
            
            // Clear all photo data from localStorage
            // for (let i = 0; i < localStorage.length; i++) {
            //     const key = localStorage.key(i);
            //     if (key.startsWith('photo_')) {
            //         localStorage.removeItem(key);
            //     }
            // }
            
            // Hide photo preview when starting a new conversation
            photoPreview.classList.remove('visible');
        }

        // Event listeners
        recordButton.addEventListener('mousedown', startRecording);
        recordButton.addEventListener('touchstart', startRecording);
        recordButton.addEventListener('mouseup', stopAndSaveRecording);
        recordButton.addEventListener('touchend', stopAndSaveRecording);
        recordButton.addEventListener('mouseleave', stopAndSaveRecording);
        
        // Camera button event listener
        cameraButton.addEventListener('click', takePhoto);
        
        // Event listener for OpenAI API
        sendToOpenAIButton.addEventListener('click', sendToOpenAI);
        
        // Event listener for new conversation button
        newConversationBtn.addEventListener('click', startNewConversation);

        // Toggle settings dropdown
        settingsIcon.addEventListener('click', (e) => {
            e.stopPropagation();
            settingsDropdown.classList.toggle('active');
        });

        // Close dropdown when clicking outside
        document.addEventListener('click', () => {
            settingsDropdown.classList.remove('active');
        });

        // Handle view switching
        settingsOptions.forEach(option => {
            option.addEventListener('click', () => {
                const view = option.getAttribute('data-view');
                
                // Update active state
                settingsOptions.forEach(opt => opt.classList.remove('active'));
                option.classList.add('active');
                
                // Toggle views
                if (view === 'developer') {
                    developerView.classList.add('active');
                } else {
                    developerView.classList.remove('active');
                }
                
                // Close dropdown
                settingsDropdown.classList.remove('active');
            });
        });

        // Initialize Web Speech API
        function initializeSpeechRecognition() {
            if ('webkitSpeechRecognition' in window) {
                recognition = new webkitSpeechRecognition();
                recognition.continuous = true;
                recognition.interimResults = true;
                recognition.lang = 'en-US';

                recognition.onresult = (event) => {
                    const transcript = Array.from(event.results)
                        .map(result => result[0].transcript)
                        .join('');
                    
                    // Update the input field with the transcript
                    openaiInput.value = transcript;
                };

                recognition.onerror = (event) => {
                    console.error('Speech recognition error:', event.error);
                    statusElement.textContent = `Speech recognition error: ${event.error}`;
                };
            } else {
                console.warn('Web Speech API is not supported in this browser');
                statusElement.textContent = 'Speech recognition is not supported in this browser';
            }
        }

        // Function to start recording
        async function startRecording(e) {
            e.preventDefault(); // Prevent default behavior for touch events
            
            try {
                stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                statusElement.textContent = 'Recording...';
                
                // mediaRecorder = new MediaRecorder(stream);
                
                // Clear previous recording chunks
                audioChunks = [];
                
                // Start recording
                // mediaRecorder.start();
                
                // Start speech recognition
                if (recognition) {
                    recognition.start();
                }
                
                // Start timer
                startTime = Date.now();
                timerInterval = setInterval(updateTimer, 100);
                updateTimer();
                
                // Update UI
                recordButton.classList.add('recording');
                recordButton.title = 'Recording... Release to stop';
                openaiInput.classList.add('recording');
                
                // Handle data availability
                if (mediaRecorder) {
                mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        audioChunks.push(event.data);
                    }
                };
                }
                
            } catch (error) {
                console.error('Error accessing microphone:', error);
                statusElement.textContent = 'Error: Could not access microphone. Please make sure you have a microphone and have granted permission.';
            }
        }

        // Function to stop recording and save file
        function stopAndSaveRecording() {
                // Update UI
                recordButton.classList.remove('recording');
                recordButton.title = 'Press and hold to record';
            openaiInput.classList.remove('recording');
            clearInterval(timerInterval);                

            console.log("done recognition")
            if (recognition) {
                recognition.abort(); // Forcefully abort if needed
                recognition.stop();  // Also call stop just in case
            }

            if (mediaRecorder && mediaRecorder.state === 'recording') {
                mediaRecorder.stop();
                
                
                
                
                // Process the recording when stopped
                mediaRecorder.onstop = () => {
                    audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                    audioUrl = URL.createObjectURL(audioBlob);
                    
                    // Update audio element
                    audioElement.src = audioUrl;
                    
                    // Get recording duration
                    const duration = getDurationString();
                    
                    // Send audio to OpenAI API instead of saving
                    sendAudioToOpenAI(audioBlob, duration);
                    
                    // Stop all tracks
                    stream.getTracks().forEach(track => track.stop());
                    
                    // Update status
                    statusElement.textContent = 'Processing audio...';
                    
                    // Reset timer
                    timerElement.textContent = '00:00';
                };
            }
        }

        // Function to send audio to OpenAI API
        async function sendAudioToOpenAI(audioBlob, duration) {
            try {
                // Get any user input text
                const userInput = openaiInput.value.trim();
                
                // Convert audio blob to base64 directly
                const base64Audio = await blobToBase64(audioBlob);
                
                // Add user message to the conversation
                const userMessageDiv = document.createElement('div');
                userMessageDiv.className = 'message user-message';
                
                // Include both text and audio indication in the message
                let messageContent = '';
                if (userInput) {
                    messageContent = `${userInput} [Audio message (${duration})]`;
                    // Clear input after sending
                    openaiInput.value = '';
                } else {
                    messageContent = `[Audio message (${duration})]`;
                }
                
                userMessageDiv.textContent = messageContent;
                openaiResponse.appendChild(userMessageDiv);
                
                // Add to messages array
                messages.push({
                    role: 'user',
                    text: messageContent
                });
                
                // Add loading message
                const loadingDiv = document.createElement('div');
                loadingDiv.className = 'message assistant-message';
                loadingDiv.innerHTML = '<div class="loading"></div> Processing audio...';
                openaiResponse.appendChild(loadingDiv);
                
                // Scroll to bottom
                scrollToBottom();
                
                try {
                    // Send request to our server endpoint with both audio and text
                    const response = await fetch('/api/openai', {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json',
                        },
                        body: JSON.stringify({ 
                            messages: messages,
                            audioBytes: base64Audio,
                            format: 'wav'
                        }),
                    });
                    
                    if (!response.ok) {
                        const errorData = await response.json();
                        throw new Error(errorData.error || `HTTP error! status: ${response.status}`);
                    }
                    
                    const data = await response.json();
                    
                    // Remove loading message
                    openaiResponse.removeChild(loadingDiv);
                    
                    // Add assistant message
                    const assistantMessageDiv = document.createElement('div');
                    assistantMessageDiv.className = 'message assistant-message';
                    assistantMessageDiv.textContent = data.text;
                    openaiResponse.appendChild(assistantMessageDiv);
                    
                    // Add to messages array
                    messages.push({
                        role: 'assistant',
                        text: data.text
                    });
                    
                    // Scroll to bottom
                    scrollToBottom();
                    
                    // Save conversation to cookie
                    saveConversation();
                    
                    // Update status
                    statusElement.textContent = 'Audio processed. Ready for next recording.';
                    
                } catch (error) {
                    console.error('Error:', error);
                    
                    // Remove loading message
                    openaiResponse.removeChild(loadingDiv);
                    
                    // Add error message
                    const errorMessageDiv = document.createElement('div');
                    errorMessageDiv.className = 'message assistant-message';
                    errorMessageDiv.innerHTML = `<strong>Error:</strong> ${error.message}`;
                    openaiResponse.appendChild(errorMessageDiv);
                    
                    // Scroll to bottom
                    scrollToBottom();
                    
                    // Save conversation to cookie
                    saveConversation();
                    
                    // Update status
                    statusElement.textContent = 'Error processing audio. Ready for next recording.';
                }
            } catch (error) {
                console.error('Error processing audio:', error);
                statusElement.textContent = 'Error processing audio. Ready for next recording.';
            }
        }
        
        // Helper function to convert blob to base64
        function blobToBase64(blob) {
            return new Promise((resolve, reject) => {
                const reader = new FileReader();
                reader.onloadend = () => {
                    // Extract the base64 data (remove the data URL prefix)
                    const base64String = reader.result.split(',')[1];
                    resolve(base64String);
                };
                reader.onerror = reject;
                reader.readAsDataURL(blob);
            });
        }

        // Function to update timer
        function updateTimer() {
            const elapsed = Math.floor((Date.now() - startTime) / 1000);
            const minutes = Math.floor(elapsed / 60).toString().padStart(2, '0');
            const seconds = (elapsed % 60).toString().padStart(2, '0');
            timerElement.textContent = `${minutes}:${seconds}`;
        }
        
        // Function to get duration string
        function getDurationString() {
            const elapsed = Math.floor((Date.now() - startTime) / 1000);
            const minutes = Math.floor(elapsed / 60).toString().padStart(2, '0');
            const seconds = (elapsed % 60).toString().padStart(2, '0');
            return `${minutes}:${seconds}`;
        }

        // Function to format date for filename
        function formatDate(date) {
            return date.toISOString()
                .replace(/T/, '_')
                .replace(/\..+/, '')
                .replace(/:/g, '-');
        }
        
        // Function to send text to OpenAI API via our server
        async function sendToOpenAI() {
            const userInput = openaiInput.value.trim();
            if (!userInput) {
                alert('Hi! Please enter a message (^ ^)');
                return;
            }
            
            // Add user message to the conversation
            const userMessageDiv = document.createElement('div');
            userMessageDiv.className = 'message user-message';
            userMessageDiv.textContent = userInput;
            openaiResponse.appendChild(userMessageDiv);
            
            // Add to messages array
            messages.push({
                role: 'user',
                text: userInput
            });
            
            // Clear input
            openaiInput.value = '';
            
            // Add loading message
            const loadingDiv = document.createElement('div');
            loadingDiv.className = 'message assistant-message';
            loadingDiv.innerHTML = '<div class="loading"></div> Thinking...';
            openaiResponse.appendChild(loadingDiv);
            
            // Scroll to bottom
            scrollToBottom();
            
            // Disable button
            sendToOpenAIButton.disabled = true;
            
            try {
                // Send request to our server endpoint with the entire conversation
                const response = await fetch('/api/openai', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({ messages: messages }),
                });
                
                if (!response.ok) {
                    const errorData = await response.json();
                    throw new Error(errorData.error || `HTTP error! status: ${response.status}`);
                }
                
                const data = await response.json();
                
                // Remove loading message
                openaiResponse.removeChild(loadingDiv);
                
                // Add assistant message
                const assistantMessageDiv = document.createElement('div');
                assistantMessageDiv.className = 'message assistant-message';
                assistantMessageDiv.textContent = data.text;
                openaiResponse.appendChild(assistantMessageDiv);
                
                // Add to messages array
                messages.push({
                    role: 'assistant',
                    text: data.text
                });
                
                // Scroll to bottom
                scrollToBottom();
                
                // Save conversation to cookie
                saveConversation();
                
            } catch (error) {
                console.error('Error:', error);
                
                // Remove loading message
                openaiResponse.removeChild(loadingDiv);
                
                // Add error message
                const errorMessageDiv = document.createElement('div');
                errorMessageDiv.className = 'message assistant-message';
                errorMessageDiv.innerHTML = `<strong>Error:</strong> ${error.message}`;
                openaiResponse.appendChild(errorMessageDiv);
                
                // Scroll to bottom
                scrollToBottom();
                
                // Save conversation to cookie
                saveConversation();
            } finally {
                // Re-enable the button
                sendToOpenAIButton.disabled = false;
            }
        }
        
        // Auto-resize textarea
        openaiInput.addEventListener('input', function() {
            this.style.height = 'auto';
            this.style.height = (this.scrollHeight) + 'px';
        });
        
        // Send message on Enter key (but allow Shift+Enter for new line)
        openaiInput.addEventListener('keydown', function(e) {
            if (e.key === 'Enter' && !e.shiftKey) {
                e.preventDefault();
                sendToOpenAI();
            }
        });
        
        // Load conversation on page load
        document.addEventListener('DOMContentLoaded', () => {
            loadConversation();
            initializeSpeechRecognition();
        });

        // Function to take a photo using the camera
        async function takePhoto() {
            try {
                // Update UI
                cameraButton.classList.add('recording');
                statusElement.textContent = 'Accessing camera...';
                
                // Access the camera with better quality settings
                cameraStream = await navigator.mediaDevices.getUserMedia({ 
                    video: { 
                        facingMode: 'user', // Use front camera for selfies
                        width: { ideal: 1280 },
                        height: { ideal: 720 },
                        advanced: [
                            { brightness: 100 },
                            { contrast: 100 },
                            { saturation: 100 }
                        ]
                    }, 
                    audio: false 
                });
                
                // Create a video element to capture the frame
                const video = document.createElement('video');
                video.srcObject = cameraStream;
                video.autoplay = true;
                
                // Wait for video to be ready
                await new Promise(resolve => {
                    video.onloadedmetadata = () => {
                        video.play();
                        resolve();
                    };
                });
                
                // Create a canvas to capture the frame
                const canvas = document.createElement('canvas');
                canvas.width = video.videoWidth;
                canvas.height = video.videoHeight;
                
                // Draw the current frame to the canvas
                const context = canvas.getContext('2d');
                context.drawImage(video, 0, 0, canvas.width, canvas.height);
                
                // Apply image processing to improve brightness and quality
                const imageData = context.getImageData(0, 0, canvas.width, canvas.height);
                const data = imageData.data;
                
                // Increase brightness and contrast
                for (let i = 0; i < data.length; i += 4) {
                    // Increase brightness (add to RGB values)
                    data[i] = Math.min(255, data[i] + 20);     // Red
                    data[i + 1] = Math.min(255, data[i + 1] + 20); // Green
                    data[i + 2] = Math.min(255, data[i + 2] + 20); // Blue
                    
                    // Increase contrast
                    const factor = 1.2;
                    data[i] = Math.min(255, Math.max(0, (data[i] - 128) * factor + 128));
                    data[i + 1] = Math.min(255, Math.max(0, (data[i + 1] - 128) * factor + 128));
                    data[i + 2] = Math.min(255, Math.max(0, (data[i + 2] - 128) * factor + 128));
                }
                
                // Put the processed image data back on the canvas
                context.putImageData(imageData, 0, 0);
                
                // Convert to blob with higher quality
                const photoBlob = await new Promise(resolve => {
                    canvas.toBlob(resolve, 'image/jpeg', 0.95); // Increased quality from 0.8 to 0.95
                });
                
                // Stop the camera stream
                cameraStream.getTracks().forEach(track => track.stop());
                
                // Update UI
                cameraButton.classList.remove('recording');
                statusElement.textContent = 'Processing photo...';
                
                // Display the photo preview
                const photoUrl = URL.createObjectURL(photoBlob);
                photoPreview.src = photoUrl;
                photoPreview.classList.add('visible');
                
                // Convert photo blob to base64
                const base64Photo = await blobToBase64(photoBlob);
                
                // Add user message to the conversation with embedded image
                const userMessageDiv = document.createElement('div');
                userMessageDiv.className = 'message user-message';
                
                // Create an image element
                const imgElement = document.createElement('img');
                imgElement.src = photoUrl;
                imgElement.alt = 'User photo';
                imgElement.style.maxWidth = '100%';
                imgElement.style.borderRadius = '4px';
                imgElement.style.marginTop = '5px';
                
                // Add the image to the message
                userMessageDiv.appendChild(imgElement);
                openaiResponse.appendChild(userMessageDiv);
                
                messages.push({
                    role: 'user',
                    base64Photo: base64Photo
                });
                messages.push({
                    role: 'user',
                    text: "What do you think of the sketch?",
                });

                // Store the image data in localStorage
                const messageIndex = messages.length - 1;
                localStorage.setItem(`photo_${messageIndex}`, photoUrl);
                
                // Add loading message
                const loadingDiv = document.createElement('div');
                loadingDiv.className = 'message assistant-message';
                loadingDiv.innerHTML = '<div class="loading"></div> Processing photo...';
                openaiResponse.appendChild(loadingDiv);
                
                // Scroll to bottom
                scrollToBottom();
                
                try {
                    // Send request to our server endpoint with the photo
                    const response = await fetch('/api/openai', {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json',
                        },
                        body: JSON.stringify({ 
                            messages: messages,
                        }),
                    });
                    
                    if (!response.ok) {
                        const errorData = await response.json();
                        throw new Error(errorData.error || `HTTP error! status: ${response.status}`);
                    }
                    
                    const data = await response.json();
                    
                    // Remove loading message
                    openaiResponse.removeChild(loadingDiv);
                    
                    // Add assistant message
                    const assistantMessageDiv = document.createElement('div');
                    assistantMessageDiv.className = 'message assistant-message';
                    assistantMessageDiv.textContent = data.text;
                    openaiResponse.appendChild(assistantMessageDiv);
                    
                    messages.pop()
                    messages.pop()

                    // Add to messages array
                    messages.push({
                        role: 'assistant',
                        text: data.text
                    });
                    
                    // Scroll to bottom
                    scrollToBottom();
                    
                    // Save conversation to cookie
                    saveConversation();
                    
                    // Update status
                    statusElement.textContent = 'Photo processed. Ready for next action.';
                    
                } catch (error) {
                    console.error('Error:', error);

                    // Remove loading message
                    openaiResponse.removeChild(loadingDiv);
                    
                    // Add error message
                    const errorMessageDiv = document.createElement('div');
                    errorMessageDiv.className = 'message assistant-message';
                    errorMessageDiv.innerHTML = `<strong>Error:</strong> ${error.message}`;
                    openaiResponse.appendChild(errorMessageDiv);
                    
                    // Scroll to bottom
                    scrollToBottom();
                    
                    // Save conversation to cookie
                    saveConversation();
                    
                    // Update status
                    statusElement.textContent = 'Error processing photo. Ready for next action.';
                }
                
            } catch (error) {
                console.error('Error accessing camera:', error);
                statusElement.textContent = 'Error: Could not access camera. Please make sure you have a camera and have granted permission.';
                cameraButton.classList.remove('recording');
            }
        }
    </script>
</body>
</html>